{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_wEGa_j4FPbz"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchvision.transforms import functional as tf\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import ToTensor, CenterCrop\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import save_image\n",
        "import segmentation_models_pytorch as sm\n",
        "import torchvision.models as models\n",
        "from segmentation_models_pytorch.losses import DiceLoss, FocalLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_MHNTjFF-_q",
        "outputId": "466226e1-5ad2-4b8d-c6ad-b720506d390e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "zipped_train = '/content/drive/MyDrive/train_seg.zip'\n",
        "z=zipfile.ZipFile(zipped_train,'r')\n",
        "z.extractall(path='/content/train')\n",
        "\n",
        "zipped_test = '/content/drive/MyDrive/test_seg.zip'\n",
        "z=zipfile.ZipFile(zipped_test,'r')\n",
        "z.extractall(path='/content/test')\n",
        "\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KaeKwYLbfTrf"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.images_dir = os.path.join(data_dir, \"images\")\n",
        "        self.masks_dir = os.path.join(data_dir, \"masks\")\n",
        "        self.ids = [os.path.splitext(file)[0] for file in os.listdir(self.images_dir)\n",
        "                    if os.path.exists(os.path.join(self.masks_dir, os.path.splitext(file)[0] + '.png'))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.ids[idx]\n",
        "        img_path = os.path.join(self.images_dir, img_id + \".jpg\")\n",
        "        mask_path = os.path.join(self.masks_dir, img_id + \".png\")\n",
        "        image = Image.open(img_path)\n",
        "        image = image.resize((img_size, img_size))\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "        mask = mask.resize((256, 256))\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C3Dg_qnOvwmk"
      },
      "outputs": [],
      "source": [
        "transformer = A.Compose([\n",
        "    A.HorizontalFlip(),\n",
        "    A.VerticalFlip(),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.407],\n",
        "                std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2(),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5HyhzTYyfTvN"
      },
      "outputs": [],
      "source": [
        "train_dir = \"/content/dat/train/train\"\n",
        "dataset = CustomImageDataset(train_dir, transformer)\n",
        "train_dataset, valid_dataset = train_test_split(dataset, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XCZi0HHH7dhv"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(valid_dataset, batch_size=4, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bYPX3EE7fyMe"
      },
      "outputs": [],
      "source": [
        "UNet = sm.Unet(\n",
        "    encoder_name=\"mobilenet_v2\",        \n",
        "    encoder_weights=\"imagenet\",\n",
        "    in_channels=3,\n",
        "    classes=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xABQGg1qBPR-"
      },
      "outputs": [],
      "source": [
        "class Loss(nn.Module):\n",
        "    def __init__(self, dice_weight=0.5, ce_weight=0.5):\n",
        "        super(Loss, self).__init__()\n",
        "\n",
        "        self.dice_criterion = DiceLoss(mode='binary')\n",
        "        self.ce_criterion = FocalLoss(mode='multiclass')\n",
        "\n",
        "        self.dice_weight = dice_weight\n",
        "        self.ce_weight = ce_weight\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "\n",
        "        dice_loss = self.dice_criterion(outputs, targets)\n",
        "        ce_loss = self.ce_criterion(outputs, targets.argmax(1))\n",
        "\n",
        "        total_loss = self.dice_weight * dice_loss + self.ce_weight * ce_loss\n",
        "\n",
        "        return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OxmxxPjIxacI"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet(3,1).to(device)\n",
        "criterion = Loss().to(device)\n",
        "optimizer = optim.Adam(model.parameters (), lr = 1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cK-Aw_8DlSi9"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (img,mask) in enumerate(dataloader):\n",
        "        img,mask = img.to(device).float(), mask.float().to(device)\n",
        "\n",
        "        pred = model(img)\n",
        "        loss = loss_fn(pred, mask)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss, current = loss.item(), (batch + 1) * len(X)\n",
        "        print(f\"loss: {loss:>7f} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqdgkPmm4p0F",
        "outputId": "cb0dc1ff-a97a-4e5f-9876-cbcab6b6a4af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.673059  [    4/ 6836]\n",
            "loss: 0.544419  [  404/ 6836]\n",
            "loss: 0.377123  [  804/ 6836]\n",
            "loss: 0.354884  [ 1204/ 6836]\n",
            "loss: 0.236219  [ 1604/ 6836]\n",
            "loss: 0.187652  [ 2004/ 6836]\n",
            "loss: 0.497534  [ 2404/ 6836]\n",
            "loss: 0.233981  [ 2804/ 6836]\n",
            "loss: 0.176436  [ 3204/ 6836]\n",
            "loss: 0.348381  [ 3604/ 6836]\n",
            "loss: 0.173597  [ 4004/ 6836]\n",
            "loss: 0.200610  [ 4404/ 6836]\n",
            "loss: 0.219469  [ 4804/ 6836]\n",
            "loss: 0.141096  [ 5204/ 6836]\n",
            "loss: 0.195525  [ 5604/ 6836]\n",
            "loss: 0.211999  [ 6004/ 6836]\n",
            "loss: 0.165298  [ 6404/ 6836]\n",
            "loss: 0.835365  [ 6804/ 6836]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.167974  [    4/ 6836]\n",
            "loss: 0.171659  [  404/ 6836]\n",
            "loss: 0.727224  [  804/ 6836]\n",
            "loss: 0.685961  [ 1204/ 6836]\n",
            "loss: 0.156356  [ 1604/ 6836]\n",
            "loss: 0.180452  [ 2004/ 6836]\n",
            "loss: 0.807187  [ 2404/ 6836]\n",
            "loss: 0.149825  [ 2804/ 6836]\n",
            "loss: 0.141525  [ 3204/ 6836]\n",
            "loss: 0.202293  [ 3604/ 6836]\n",
            "loss: 0.203141  [ 4004/ 6836]\n",
            "loss: 0.106428  [ 4404/ 6836]\n",
            "loss: 0.147435  [ 4804/ 6836]\n",
            "loss: 0.130286  [ 5204/ 6836]\n",
            "loss: 0.123556  [ 5604/ 6836]\n",
            "loss: 0.113962  [ 6004/ 6836]\n",
            "loss: 0.155875  [ 6404/ 6836]\n",
            "loss: 0.166146  [ 6804/ 6836]\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 2\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_loader, model, criterion, optimizer)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "I5Sf9gYe3xZf"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device).float(), y.to(device).float()\n",
        "\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyiUrK-B2Ov2",
        "outputId": "aa747b09-6953-4b62-f04a-72a0ee61a744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.120008  [    4/ 1207]\n",
            "loss: 0.148046  [  404/ 1207]\n",
            "loss: 0.334199  [  804/ 1207]\n",
            "loss: 0.174412  [ 1204/ 1207]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.155289  [    4/ 1207]\n",
            "loss: 0.147005  [  404/ 1207]\n",
            "loss: 0.292492  [  804/ 1207]\n",
            "loss: 0.244786  [ 1204/ 1207]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.760643  [    4/ 1207]\n",
            "loss: 0.192845  [  404/ 1207]\n",
            "loss: 0.554432  [  804/ 1207]\n",
            "loss: 0.097973  [ 1204/ 1207]\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 3\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(val_loader, model, criterion, optimizer)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "sZ86eU1BZxwL"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0,0,0],\n",
        "                         std=[1, 1, 1])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "YXPjum3Bna0j"
      },
      "outputs": [],
      "source": [
        "images_dir = '/content/dat/test/images'\n",
        "masks_dir = '/content/dat/test/mask'\n",
        "os.makedirs(masks_dir, exist_ok=True)\n",
        "image_filenames = os.listdir(images_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "f2XzI-h0mwnR"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.functional import to_pil_image\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for image in image_filenames:\n",
        "        image_path = os.path.join(images_dir, image)\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "        img = transform(img).unsqueeze(0).to(device)\n",
        "        predicted_mask = model(img)\n",
        "        predicted_mask = torch.sigmoid(predicted_mask)\n",
        "        predicted_mask = (predicted_mask > 0.5).float()\n",
        "        predicted_mask = to_pil_image(predicted_mask.squeeze().cpu())\n",
        "        mask = os.path.splitext(image)[0] + '.png'\n",
        "        mask_path = os.path.join(masks_dir, mask)\n",
        "        predicted_mask.save(mask_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MD6Nb-ElifaH",
        "outputId": "63808a56-2182-4c38-f7fb-55611ab5cbd2"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e5617f84-9b51-47e6-9a3c-8ea7daec0d1d\", \"masks.zip\", 2300362)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/masks.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niHDxl1n8qdT"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
